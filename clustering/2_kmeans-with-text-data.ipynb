{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will\n",
    "* Cluster Wikipedia documents using k-means\n",
    "* Explore the role of random initialization on the quality of the clustering\n",
    "* Explore how results differ after changing the number of clusters\n",
    "* Evaluate clustering, both quantitatively and qualitatively\n",
    "\n",
    "When properly executed, clustering uncovers valuable insights from a set of unlabeled documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with text data, we must first convert the documents into numerical features. As in the first assignment, let's extract TF-IDF features for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = pd.read_csv('people_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader=np.load(filename)\n",
    "    data=loader['data']\n",
    "    indices=loader['indices']\n",
    "    indptr=loader['indptr']\n",
    "    shape=loader['shape']\n",
    "    \n",
    "    return csr_matrix((data, indices, indptr),shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf=load_sparse_csr('people_wiki_tf_idf.npz')\n",
    "map_index_to_word=pd.read_json('people_wiki_map_index_to_word.json',typ='series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainder of the assignment, we will use sparse matrices. Sparse matrices are matrices that have a small number of nonzero entries. A good data structure for sparse matrices would only store the nonzero entries to save space and speed up computation. SciPy provides a highly-optimized library for sparse matrices. Many matrix operations available for NumPy arrays are also available for SciPy sparse matrices.\n",
    "\n",
    "We first convert the TF-IDF column (in dictionary format) into the SciPy sparse matrix format. We included plenty of comments for the curious; if you'd like, you may skip the next block and treat the function as a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix contains a TF-IDF score for each of the 59071 pages in the data set and each of the 547979 unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize all vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the previous assignment, Euclidean distance can be a poor metric of similarity between documents, as it unfairly penalizes long articles. For a reasonable assessment of similarity, we should disregard the length information and use length-agnostic metrics, such as cosine distance.\n",
    "\n",
    "The k-means algorithm does not directly work with cosine distance, so we take an alternative route to remove length information: we normalize all vectors to be unit length. It turns out that Euclidean distance closely mimics cosine distance when all vectors are unit length. In particular, the squared Euclidean distance between any two vectors of length one is directly proportional to their cosine distance.\n",
    "\n",
    "We can prove this as follows. Let $\\mathbf{x}$ and $\\mathbf{y}$ be normalized vectors, i.e. unit vectors, so that $\\|\\mathbf{x}\\|=\\|\\mathbf{y}\\|=1$. Write the squared Euclidean distance as the dot product of $(\\mathbf{x} - \\mathbf{y})$ to itself:\n",
    "\\begin{align*}\n",
    "\\|\\mathbf{x} - \\mathbf{y}\\|^2 &= (\\mathbf{x} - \\mathbf{y})^T(\\mathbf{x} - \\mathbf{y})\\\\\n",
    "                              &= (\\mathbf{x}^T \\mathbf{x}) - 2(\\mathbf{x}^T \\mathbf{y}) + (\\mathbf{y}^T \\mathbf{y})\\\\\n",
    "                              &= \\|\\mathbf{x}\\|^2 - 2(\\mathbf{x}^T \\mathbf{y}) + \\|\\mathbf{y}\\|^2\\\\\n",
    "                              &= 2 - 2(\\mathbf{x}^T \\mathbf{y})\\\\\n",
    "                              &= 2(1 - (\\mathbf{x}^T \\mathbf{y}))\\\\\n",
    "                              &= 2\\left(1 - \\frac{\\mathbf{x}^T \\mathbf{y}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}\\right)\\\\\n",
    "                              &= 2\\left[\\text{cosine distance}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "This tells us that two **unit vectors** that are close in Euclidean distance are also close in cosine distance. Thus, the k-means algorithm (which naturally uses Euclidean distances) on normalized vectors will produce the same results as clustering using cosine distance as a distance metric.\n",
    "\n",
    "We import the [`normalize()` function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) from scikit-learn to normalize all vectors to unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "tf_idf = normalize(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement the k-means algorithm. First, we choose an initial set of centroids. A common practice is to choose randomly from the data points.\n",
    "\n",
    "**Note:** We specify a seed here, so that everyone gets the same answer. In practice, we highly recommend to use different seeds every time (for instance, by using the current timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_centroids(data, k, seed=None):\n",
    "    '''Randomly choose k data points as initial centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    n = data.shape[0] # number of data points\n",
    "        \n",
    "    # Pick K indices from range [0, N).\n",
    "    rand_indices = np.random.randint(0, n, k)\n",
    "    \n",
    "    # Keep centroids as dense format, as many entries will be nonzero due to averaging.\n",
    "    # As long as at least one document in a cluster contains a word,\n",
    "    # it will carry a nonzero weight in the TF-IDF vector of the centroid.\n",
    "    centroids = data[rand_indices,:].toarray()\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialization, the k-means algorithm iterates between the following two steps:\n",
    "1. Assign each data point to the closest centroid.\n",
    "$$\n",
    "z_i \\gets \\mathrm{argmin}_j \\|\\mu_j - \\mathbf{x}_i\\|^2\n",
    "$$\n",
    "2. Revise centroids as the mean of the assigned data points.\n",
    "$$\n",
    "\\mu_j \\gets \\frac{1}{n_j}\\sum_{i:z_i=j} \\mathbf{x}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pseudocode, we iteratively do the following:\n",
    "```\n",
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "centroids = revise_centroids(data, k, cluster_assignment)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we implement Step 1 of the main k-means loop above? First import `pairwise_distances` function from scikit-learn, which calculates Euclidean distances between rows of given arrays. See [this documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html) for more information.\n",
    "\n",
    "For the sake of demonstration, let's look at documents 100 through 102 as query documents and compute the distances between each of these documents and every other document in the corpus. In the k-means algorithm, we will have to compute pairwise distances between the set of centroids and the set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.41000789  1.36894636]\n",
      " [ 1.40935215  1.41023886]\n",
      " [ 1.39855967  1.40890299]\n",
      " ..., \n",
      " [ 1.41108296  1.39123646]\n",
      " [ 1.41022804  1.31468652]\n",
      " [ 1.39899784  1.41072448]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Get the TF-IDF vectors for documents 100 through 102.\n",
    "queries = tf_idf[100:102,:]\n",
    "\n",
    "# Compute pairwise distances from every data point to each query vector.\n",
    "dist = pairwise_distances(tf_idf, queries, metric='euclidean')\n",
    "\n",
    "print dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, `dist[i,j]` is assigned the distance between the `i`th row of `X` (i.e., `X[i,:]`) and the `j`th row of `Y` (i.e., `Y[j,:]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For a moment, suppose that we initialize three centroids with the first 3 rows of `tf_idf`. Write code to compute distances from each of the centroids to all data points in `tf_idf`. Then find the distance between row 430 of `tf_idf` and the second centroid and save it to `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.40713107]]\n"
     ]
    }
   ],
   "source": [
    "# Students should write code here\n",
    "queries=tf_idf[0:3]\n",
    "\n",
    "distances=pairwise_distances(tf_idf, queries, metric='euclidean')\n",
    "dist = pairwise_distances(tf_idf[430: 431],queries[1],metric='euclidean')\n",
    "print dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.40775177,  1.38784582],\n",
       "       [ 1.40775177,  0.        ,  1.39867641],\n",
       "       [ 1.38784582,  1.39867641,  0.        ],\n",
       "       ..., \n",
       "       [ 1.37070999,  1.40978937,  1.40616385],\n",
       "       [ 1.35214578,  1.41306211,  1.40869799],\n",
       "       [ 1.40799024,  1.41353429,  1.40903605]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "if np.allclose(dist, pairwise_distances(tf_idf[430,:], tf_idf[1,:])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Next, given the pairwise distances, we take the minimum of the distances for each data point. Fittingly, NumPy provides an `argmin` function. See [this documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argmin.html) for details.\n",
    "\n",
    "Read the documentation and write code to produce a 1D array whose i-th entry indicates the centroid that is the closest to the i-th data point. Use the list of distances from the previous checkpoint and save them as `distances`. The value 0 indicates closeness to the first centroid, 1 indicates closeness to the second centroid, and so forth. Save this array as `closest_cluster`.\n",
    "\n",
    "**Hint:** the resulting array should be as long as the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Students should write code here\n",
    "closest_cluster=np.argmin(distances, axis=1)\n",
    "closest_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "reference = [list(row).index(min(row)) for row in distances]\n",
    "if np.allclose(closest_cluster, reference):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Let's put these steps together.  First, initialize three centroids with the first 3 rows of `tf_idf`. Then, compute distances from each of the centroids to all data points in `tf_idf`. Finally, use these distance calculations to compute cluster assignments and assign them to `cluster_assignment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids=tf_idf[0:3,:]\n",
    "distances=pairwise_distances(tf_idf, centroids)\n",
    "distances\n",
    "len(distances)\n",
    "distances[100]\n",
    "np.argmin(distances[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.40775177,  1.38784582],\n",
       "       [ 1.40775177,  0.        ,  1.39867641],\n",
       "       [ 1.38784582,  1.39867641,  0.        ],\n",
       "       ..., \n",
       "       [ 1.37070999,  1.40978937,  1.40616385],\n",
       "       [ 1.35214578,  1.41306211,  1.40869799],\n",
       "       [ 1.40799024,  1.41353429,  1.40903605]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids=tf_idf[0:3,:]\n",
    "distances=pairwise_distances(tf_idf, centroids)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59071"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[100]\n",
    "np.argmin(distances[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Students should write code here\n",
    "def arg(distances):\n",
    "    cluster_assignment = list()\n",
    "    for i in range(0,len(distances)):\n",
    "        cluster_assignment.append(np.argmin(distances[i]))\n",
    "    return np.array(cluster_assignment)\n",
    "centroids = tf_idf[0:3,:]\n",
    "distances = pairwise_distances(tf_idf,centroids)\n",
    "cluster_assignment = arg(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "if len(cluster_assignment)==59071 and \\\n",
    "   np.array_equal(np.bincount(cluster_assignment), np.array([23061, 10086, 25924])):\n",
    "    print('Pass') # count number of data points for each cluster\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23061, 10086, 25924])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59071"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.bincount(cluster_assignment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks in this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_clusters(data, centroids):\n",
    "    \n",
    "    # Compute distances between each data point and the set of centroids:\n",
    "    # Fill in the blank (RHS only)\n",
    "    distances_from_centroids = pairwise_distances(data,centroids)\n",
    "    \n",
    "    # Compute cluster assignments for each data point:\n",
    "    # Fill in the blank (RHS only)\n",
    "    cluster_assignment = np.argmin(distances_from_centroids, axis=1)\n",
    "    \n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. For the last time, let us check if Step 1 was implemented correctly. With rows 0, 2, 4, and 6 of `tf_idf` as an initial set of centroids, we assign cluster labels to rows 0, 10, 20, ..., and 90 of `tf_idf`. The resulting cluster labels should be `[0, 1, 1, 0, 0, 2, 0, 2, 2, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "if np.allclose(assign_clusters(tf_idf[0:100:10], tf_idf[0:8:2]), np.array([0, 1, 1, 0, 0, 2, 0, 2, 2, 1])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revising clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn to Step 2, where we compute the new centroids given the cluster assignments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy and NumPy arrays allow for filtering via Boolean masks. For instance, we filter all data points that are assigned to cluster 0 by writing\n",
    "```\n",
    "data[cluster_assignment==0,:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop intuition about filtering, let's look at a toy example consisting of 3 data points and 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[1., 2., 0.],\n",
    "                 [0., 0., 0.],\n",
    "                 [2., 2., 0.]])\n",
    "centroids = np.array([[0.5, 0.5, 0.],\n",
    "                      [0., -0.5, 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign these data points to the closest centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "print cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `cluster_assignment==1` gives a list of Booleans that says whether each data point is assigned to cluster 1 or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise for cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lieu of indices, we can put in the list of Booleans to pick and choose rows. Only the rows that correspond to a `True` entry will be retained.\n",
    "\n",
    "First, let's look at the data points (i.e., their values) assigned to cluster 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense since [0 0 0] is closer to [0 -0.5 0] than to [0.5 0.5 0].\n",
    "\n",
    "Now let's look at the data points assigned to cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  0.],\n",
       "       [ 2.,  2.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this makes sense since these values are each closer to [0.5 0.5 0] than to [0 -0.5 0].\n",
    "\n",
    "Given all the data points in a cluster, it only remains to compute the mean. Use [np.mean()](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.mean.html). By default, the function averages all elements in a 2D array. To compute row-wise or column-wise means, add the `axis` argument. See the linked documentation for details. \n",
    "\n",
    "Use this function to average the data points in cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5,  2. ,  0. ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to complete this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def revise_centroids(data, k, cluster_assignment):\n",
    "    new_centroids = []\n",
    "    for i in xrange(k):\n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment==i]\n",
    "        # Compute the mean of the data points. Fill in the blank (RHS only)\n",
    "        centroid = member_data_points.mean(axis=0)\n",
    "        \n",
    "        # Convert numpy.matrix type to numpy.ndarray type\n",
    "        centroid = centroid.A1\n",
    "        new_centroids.append(centroid)\n",
    "    new_centroids = np.array(new_centroids)\n",
    "    \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. Let's check our Step 2 implementation. Letting rows 0, 10, ..., 90 of `tf_idf` as the data points and the cluster labels `[0, 1, 1, 0, 0, 2, 0, 2, 2, 1]`, we compute the next set of centroids. Each centroid is given by the average of all member data points in corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = revise_centroids(tf_idf[0:100:10], 3, np.array([0, 1, 1, 0, 0, 2, 0, 2, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.50008938e-04,   8.46265596e-05,   2.38278645e-05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.72572638e-05,   6.98529765e-05,   1.99263190e-05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.01598466e-04,   8.08230804e-05,   1.77362711e-05]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "result = revise_centroids(tf_idf[0:100:10], 3, np.array([0, 1, 1, 0, 0, 2, 0, 2, 2, 1]))\n",
    "if np.allclose(result[0], np.mean(tf_idf[[0,30,40,60]].toarray(), axis=0)) and \\\n",
    "   np.allclose(result[1], np.mean(tf_idf[[10,20,90]].toarray(), axis=0))   and \\\n",
    "   np.allclose(result[2], np.mean(tf_idf[[50,70,80]].toarray(), axis=0)):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we tell if the k-means algorithm is converging? We can look at the cluster assignments and see if they stabilize over time. In fact, we'll be running the algorithm until the cluster assignments stop changing at all. To be extra safe, and to assess the clustering performance, we'll be looking at an additional criteria: the sum of all squared distances between data points and centroids. This is defined as\n",
    "$$\n",
    "J(\\mathcal{Z},\\mu) = \\sum_{j=1}^k \\sum_{i:z_i = j} \\|\\mathbf{x}_i - \\mu_j\\|^2.\n",
    "$$\n",
    "The smaller the distances, the more homogeneous the clusters are. In other words, we'd like to have \"tight\" clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0. , -0.5,  0. ])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[centroids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_heterogeneity(data, k, centroids, cluster_assignment):\n",
    "    \n",
    "    heterogeneity = 0.0\n",
    "    for i in xrange(k):\n",
    "        \n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment==i, :]\n",
    "        \n",
    "        if member_data_points.shape[0] > 0: # check if i-th cluster is non-empty\n",
    "            # Compute distances from centroid to data points (RHS only)\n",
    "            distances = pairwise_distances(member_data_points, [centroids[i]], metric='euclidean')\n",
    "            squared_distances = distances**2\n",
    "            heterogeneity += np.sum(squared_distances)\n",
    "        \n",
    "    return heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the cluster heterogeneity for the 2-cluster example we've been considering based on our current cluster assignments and centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 2.,  2.,  0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0. , -0.5,  0. ])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[centroids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0. ],\n",
       "       [ 0. , -0.5,  0. ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.25"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_heterogeneity(data, 2, centroids, cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining into a single function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the two k-means steps have been implemented, as well as our heterogeneity metric we wish to monitor, it is only a matter of putting these functions together to write a k-means algorithm that\n",
    "\n",
    "* Repeatedly performs Steps 1 and 2\n",
    "* Tracks convergence metrics\n",
    "* Stops if either no assignment changed or we reach a certain number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in the blanks\n",
    "def kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False):\n",
    "    '''This function runs k-means on given data and initial set of centroids.\n",
    "       maxiter: maximum number of iterations to run.\n",
    "       record_heterogeneity: (optional) a list, to store the history of heterogeneity as function of iterations\n",
    "                             if None, do not store the history.\n",
    "       verbose: if True, print how many data points changed their cluster labels in each iteration'''\n",
    "    centroids = initial_centroids[:]\n",
    "    prev_cluster_assignment = None\n",
    "    \n",
    "    for itr in xrange(maxiter):        \n",
    "        if verbose:\n",
    "            print(itr)\n",
    "        \n",
    "        # 1. Make cluster assignments using nearest centroids\n",
    "        cluster_assignment = assign_clusters(data, centroids)\n",
    "            \n",
    "        # 2. Compute a new centroid for each of the k clusters, averaging all data points assigned to that cluster.\n",
    "        centroids = revise_centroids(data, k, cluster_assignment)\n",
    "            \n",
    "        # Check for convergence: if none of the assignments changed, stop\n",
    "        if prev_cluster_assignment is not None and \\\n",
    "          (prev_cluster_assignment==cluster_assignment).all():\n",
    "            break\n",
    "        \n",
    "        # Print number of new assignments \n",
    "        if prev_cluster_assignment is not None:\n",
    "            num_changed = np.sum(prev_cluster_assignment!=cluster_assignment)\n",
    "            if verbose:\n",
    "                print('    {0:5d} elements changed their cluster assignment.'.format(num_changed))   \n",
    "        \n",
    "        # Record heterogeneity convergence metric\n",
    "        if record_heterogeneity is not None:\n",
    "            # YOUR CODE HERE\n",
    "            score = compute_heterogeneity(data,k, centroids, cluster_assignment)\n",
    "            record_heterogeneity.append(score)\n",
    "        \n",
    "        prev_cluster_assignment = cluster_assignment[:]\n",
    "        \n",
    "    return centroids, cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting convergence metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the above function to plot the convergence metric across iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_heterogeneity(heterogeneity, k):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(heterogeneity, linewidth=4)\n",
    "    plt.xlabel('# Iterations')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('Heterogeneity of clustering over time, K={0:d}'.format(k))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider running k-means with K=3 clusters for a maximum of 400 iterations, recording cluster heterogeneity at every step.  Then, let's plot the heterogeneity over iterations using the plotting function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "    19157 elements changed their cluster assignment.\n",
      "2\n",
      "     7739 elements changed their cluster assignment.\n",
      "3\n",
      "     5119 elements changed their cluster assignment.\n",
      "4\n",
      "     3370 elements changed their cluster assignment.\n",
      "5\n",
      "     2811 elements changed their cluster assignment.\n",
      "6\n",
      "     3233 elements changed their cluster assignment.\n",
      "7\n",
      "     3815 elements changed their cluster assignment.\n",
      "8\n",
      "     3172 elements changed their cluster assignment.\n",
      "9\n",
      "     1149 elements changed their cluster assignment.\n",
      "10\n",
      "      498 elements changed their cluster assignment.\n",
      "11\n",
      "      265 elements changed their cluster assignment.\n",
      "12\n",
      "      149 elements changed their cluster assignment.\n",
      "13\n",
      "      100 elements changed their cluster assignment.\n",
      "14\n",
      "       76 elements changed their cluster assignment.\n",
      "15\n",
      "       67 elements changed their cluster assignment.\n",
      "16\n",
      "       51 elements changed their cluster assignment.\n",
      "17\n",
      "       47 elements changed their cluster assignment.\n",
      "18\n",
      "       40 elements changed their cluster assignment.\n",
      "19\n",
      "       34 elements changed their cluster assignment.\n",
      "20\n",
      "       35 elements changed their cluster assignment.\n",
      "21\n",
      "       39 elements changed their cluster assignment.\n",
      "22\n",
      "       24 elements changed their cluster assignment.\n",
      "23\n",
      "       16 elements changed their cluster assignment.\n",
      "24\n",
      "       12 elements changed their cluster assignment.\n",
      "25\n",
      "       14 elements changed their cluster assignment.\n",
      "26\n",
      "       17 elements changed their cluster assignment.\n",
      "27\n",
      "       15 elements changed their cluster assignment.\n",
      "28\n",
      "       14 elements changed their cluster assignment.\n",
      "29\n",
      "       16 elements changed their cluster assignment.\n",
      "30\n",
      "       21 elements changed their cluster assignment.\n",
      "31\n",
      "       22 elements changed their cluster assignment.\n",
      "32\n",
      "       33 elements changed their cluster assignment.\n",
      "33\n",
      "       35 elements changed their cluster assignment.\n",
      "34\n",
      "       39 elements changed their cluster assignment.\n",
      "35\n",
      "       36 elements changed their cluster assignment.\n",
      "36\n",
      "       36 elements changed their cluster assignment.\n",
      "37\n",
      "       25 elements changed their cluster assignment.\n",
      "38\n",
      "       27 elements changed their cluster assignment.\n",
      "39\n",
      "       25 elements changed their cluster assignment.\n",
      "40\n",
      "       28 elements changed their cluster assignment.\n",
      "41\n",
      "       35 elements changed their cluster assignment.\n",
      "42\n",
      "       31 elements changed their cluster assignment.\n",
      "43\n",
      "       25 elements changed their cluster assignment.\n",
      "44\n",
      "       18 elements changed their cluster assignment.\n",
      "45\n",
      "       15 elements changed their cluster assignment.\n",
      "46\n",
      "       10 elements changed their cluster assignment.\n",
      "47\n",
      "        8 elements changed their cluster assignment.\n",
      "48\n",
      "        8 elements changed their cluster assignment.\n",
      "49\n",
      "        8 elements changed their cluster assignment.\n",
      "50\n",
      "        7 elements changed their cluster assignment.\n",
      "51\n",
      "        8 elements changed their cluster assignment.\n",
      "52\n",
      "        3 elements changed their cluster assignment.\n",
      "53\n",
      "        3 elements changed their cluster assignment.\n",
      "54\n",
      "        4 elements changed their cluster assignment.\n",
      "55\n",
      "        2 elements changed their cluster assignment.\n",
      "56\n",
      "        3 elements changed their cluster assignment.\n",
      "57\n",
      "        3 elements changed their cluster assignment.\n",
      "58\n",
      "        1 elements changed their cluster assignment.\n",
      "59\n",
      "        1 elements changed their cluster assignment.\n",
      "60\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAELCAYAAAASgBUgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2szMrAU5QJuZmbUgB2gzM7MW9P8BUqi4NETrQM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105dd4c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 3\n",
    "heterogeneity = []\n",
    "initial_centroids = get_initial_centroids(tf_idf, k, seed=0)\n",
    "centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                       record_heterogeneity=heterogeneity, verbose=True)\n",
    "plot_heterogeneity(heterogeneity, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. (True/False) The clustering objective (heterogeneity) is non-increasing for this example.\n",
    "\n",
    "True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Let's step back from this particular example. If the clustering objective (heterogeneity) would ever increase when running k-means, that would indicate: (choose one)\n",
    "\n",
    "1\n",
    "\n",
    "1. k-means algorithm got stuck in a bad local minimum\n",
    "2. There is a bug in the k-means code\n",
    "3. All data points consist of exact duplicates\n",
    "4. Nothing is wrong. The objective should generally go down sooner or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the cluster contains the greatest number of data points in the end? Hint: Use [`np.bincount()`](http://docs.scipy.org/doc/numpy-1.11.0/reference/generated/numpy.bincount.html) to count occurrences of each cluster label.\n",
    "\n",
    "2\n",
    " 1. Cluster #0\n",
    " 2. Cluster #1\n",
    " 3. Cluster #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19595, 10427, 29049])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of local maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weakness of k-means is that it tends to get stuck in a local minimum. To see this, let us run k-means multiple times, with different initial centroids created using different random seeds.\n",
    "\n",
    "**Note:** Again, in practice, you should set different seeds for every run. We give you a list of seeds for this assignment so that everyone gets the same answer.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18047\n",
      "seed=000000, heterogeneity=57457.52442\n",
      "15779\n",
      "seed=020000, heterogeneity=57533.20100\n",
      "18132\n",
      "seed=040000, heterogeneity=57512.69257\n",
      "17900\n",
      "seed=060000, heterogeneity=57466.97925\n",
      "17582\n",
      "seed=080000, heterogeneity=57494.92990\n",
      "16969\n",
      "seed=100000, heterogeneity=57484.42210\n",
      "16481\n",
      "seed=120000, heterogeneity=57554.62410\n",
      "365.648550034\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "heterogeneity = {}\n",
    "import time\n",
    "start = time.time()\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = get_initial_centroids(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    print max(np.bincount(cluster_assignment))\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "    sys.stdout.flush()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the variation in heterogeneity for different initializations. This indicates that k-means sometimes gets stuck at a bad local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Another way to capture the effect of changing initialization is to look at the distribution of cluster assignments. Add a line to the code above to compute the size (# of member data points) of clusters for each run of k-means. Look at the size of the largest cluster (most # of member data points) across multiple runs, with seeds 0, 20000, ..., 120000. How much does this measure vary across the runs? What is the minimum and maximum values this quantity takes?\n",
    "\n",
    "15779     18132\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One effective way to counter this tendency is to use **k-means++** to provide a smart initialization. This method tries to spread out the initial set of centroids so that they are not too close together. It is known to improve the quality of local optima and lower average runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smart_initialize(data, k, seed=None):\n",
    "    '''Use k-means++ to initialize a good set of centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    centroids = np.zeros((k, data.shape[1]))\n",
    "    \n",
    "    # Randomly choose the first centroid.\n",
    "    # Since we have no prior knowledge, choose uniformly at random\n",
    "    idx = np.random.randint(data.shape[0])\n",
    "    centroids[0] = data[idx,:].toarray()\n",
    "    # Compute distances from the first centroid chosen to all the other data points\n",
    "    squared_distances = pairwise_distances(data, centroids[0:1], metric='euclidean').flatten()**2\n",
    "    \n",
    "    for i in xrange(1, k):\n",
    "        # Choose the next centroid randomly, so that the probability for each data point to be chosen\n",
    "        # is directly proportional to its squared distance from the nearest centroid.\n",
    "        # Roughtly speaking, a new centroid should be as far as from other centroids as possible.\n",
    "        idx = np.random.choice(data.shape[0], 1, p=squared_distances/sum(squared_distances))\n",
    "        centroids[i] = data[idx,:].toarray()\n",
    "        # Now compute distances from the centroids to all data points\n",
    "        squared_distances = np.min(pairwise_distances(data, centroids[0:i+1], metric='euclidean')**2,axis=1)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now rerun k-means with 10 clusters using the same set of seeds, but always using k-means++ to initialize the algorithm.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=57468.63808\n",
      "seed=020000, heterogeneity=57486.94263\n",
      "seed=040000, heterogeneity=57454.35926\n",
      "seed=060000, heterogeneity=57530.43659\n",
      "seed=080000, heterogeneity=57454.51852\n",
      "seed=100000, heterogeneity=57471.56674\n",
      "seed=120000, heterogeneity=57523.28839\n",
      "440.201977015\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "heterogeneity_smart = {}\n",
    "start = time.time()\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = smart_initialize(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity_smart[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity_smart[seed]))\n",
    "    sys.stdout.flush()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the set of cluster heterogeneities we got from our 7 restarts of k-means using random initialization compared to the 7 restarts of k-means using k-means++ as a smart initialization.\n",
    "\n",
    "The following code produces a [box plot](http://matplotlib.org/api/pyplot_api.html) for each of these methods, indicating the spread of values produced by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAFTCAYAAAD4N0wZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d77e250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot([heterogeneity.values(), heterogeneity_smart.values()], vert=False)\n",
    "plt.yticks([1, 2], ['k-means', 'k-means++'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice from the box plot:\n",
    "* On average, k-means++ produces a better clustering than Random initialization.\n",
    "* Variation in clustering quality is smaller for k-means++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In general, you should run k-means at least a few times with different initializations and then return the run resulting in the lowest heterogeneity.** Let us write a function that runs k-means multiple times and picks the best run that minimizes heterogeneity. The function accepts an optional list of seed values to be used for the multiple runs; if no such list is provided, the current UTC time is used as seed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_multiple_runs(data, k, maxiter, num_runs, seed_list=None, verbose=False):\n",
    "    heterogeneity = {}\n",
    "    \n",
    "    min_heterogeneity_achieved = float('inf')\n",
    "    best_seed = None\n",
    "    final_centroids = None\n",
    "    final_cluster_assignment = None\n",
    "    \n",
    "    for i in xrange(num_runs):\n",
    "        \n",
    "        # Use UTC time if no seeds are provided \n",
    "        if seed_list is not None: \n",
    "            seed = seed_list[i]\n",
    "            np.random.seed(seed)\n",
    "        else: \n",
    "            seed = int(time.time())\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Use k-means++ initialization\n",
    "        initial_centroids = smart_initialize(data,k,seed)\n",
    "        \n",
    "        # Run k-means\n",
    "        centroids, cluster_assignment = kmeans(data, k, initial_centroid, maxiter, heterogeneity, \n",
    "                                              verbose)\n",
    "        \n",
    "        # To save time, compute heterogeneity only once in the end\n",
    "        heterogeneity[seed] = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "        \n",
    "        if verbose:\n",
    "            print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        # if current measurement of heterogeneity is lower than previously seen,\n",
    "        # update the minimum record of heterogeneity.\n",
    "        if heterogeneity[seed] < min_heterogeneity_achieved:\n",
    "            min_heterogeneity_achieved = heterogeneity[seed]\n",
    "            best_seed = seed\n",
    "            final_centroids = centroids\n",
    "            final_cluster_assignment = cluster_assignment\n",
    "    \n",
    "    # Return the centroids and cluster assignments that minimize heterogeneity.\n",
    "    return final_centroids, final_cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are measuring the tightness of the clusters, a higher value of K reduces the possible heterogeneity metric by definition.  For example, if we have N data points and set K=N clusters, then we could have 0 cluster heterogeneity by setting the N centroids equal to the values of the N data points. (Note: Not all runs for larger K will result in lower heterogeneity than a single run with smaller K due to local optima.)  Let's explore this general trend for ourselves by performing the following analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `kmeans_multiple_runs` function to run k-means with five different values of K.  For each K, use k-means++ and multiple runs to pick the best solution.  In what follows, we consider K=2,10,25,50,100 and 7 restarts for each setting.\n",
    "\n",
    "**IMPORTANT: The code block below will take about one hour to finish. We highly suggest that you use the arrays that we have computed for you.**\n",
    "\n",
    "Side note: In practice, a good implementation of k-means would utilize parallelism to run multiple runs of k-means at once. For an example, see [scikit-learn's KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "#    plt.figure(figsize=(7,4))\n",
    "#    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "#    plt.xlabel('K')\n",
    "#    plt.ylabel('Heterogeneity')\n",
    "#    plt.title('K vs. Heterogeneity')\n",
    "#    plt.rcParams.update({'font.size': 16})\n",
    "#    plt.tight_layout()\n",
    "\n",
    "#start = time.time()\n",
    "#centroids = {}\n",
    "#cluster_assignment = {}\n",
    "#heterogeneity_values = []\n",
    "#k_list = [2, 10, 25, 50, 100]\n",
    "#seed_list = [0, 20000, 40000, 60000, 80000, 100000, 120000]\n",
    "\n",
    "#for k in k_list:\n",
    "#    heterogeneity = []\n",
    "#    centroids[k], cluster_assignment[k] = kmeans_multiple_runs(tf_idf, k, maxiter=400,\n",
    "#                                                               num_runs=len(seed_list),\n",
    "#                                                               seed_list=seed_list,\n",
    "#                                                               verbose=True)\n",
    "#    score = compute_heterogeneity(tf_idf, k, centroids[k], cluster_assignment[k])\n",
    "#    heterogeneity_values.append(score)\n",
    "\n",
    "#plot_k_vs_heterogeneity(k_list, heterogeneity_values)\n",
    "\n",
    "#end = time.time()\n",
    "#print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the pre-computed NumPy arrays, first download kmeans-arrays.npz as mentioned in the reading for this assignment and load them with the following code.  Make sure the downloaded file is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAELCAYAAADqYO7XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCKmZCwiIhIxJWMREZGI/T8/GR+FX+81UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1105155d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('K vs. Heterogeneity')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()\n",
    "\n",
    "filename = 'kmeans-arrays.npz'\n",
    "\n",
    "heterogeneity_values = []\n",
    "k_list = [2, 10, 25, 50, 100]\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    arrays = np.load(filename)\n",
    "    centroids = {}\n",
    "    cluster_assignment = {}\n",
    "    for k in k_list:\n",
    "        print k\n",
    "        sys.stdout.flush()\n",
    "        '''To save memory space, do not load the arrays from the file right away. We use\n",
    "           a technique known as lazy evaluation, where some expressions are not evaluated\n",
    "           until later. Any expression appearing inside a lambda function doesn't get\n",
    "           evaluated until the function is called.\n",
    "           Lazy evaluation is extremely important in memory-constrained setting, such as\n",
    "           an Amazon EC2 t2.micro instance.'''\n",
    "        centroids[k] = lambda k=k: arrays['centroids_{0:d}'.format(k)]\n",
    "        cluster_assignment[k] = lambda k=k: arrays['cluster_assignment_{0:d}'.format(k)]\n",
    "        score = compute_heterogeneity(tf_idf, k, centroids[k](), cluster_assignment[k]())\n",
    "        heterogeneity_values.append(score)\n",
    "    \n",
    "    plot_k_vs_heterogeneity(k_list, heterogeneity_values)\n",
    "\n",
    "else:\n",
    "    print('File not found. Skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: <function __main__.<lambda>>,\n",
       " 10: <function __main__.<lambda>>,\n",
       " 25: <function __main__.<lambda>>,\n",
       " 50: <function __main__.<lambda>>,\n",
       " 100: <function __main__.<lambda>>}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we show that heterogeneity goes down as we increase the number of clusters. Does this mean we should always favor a higher K? **Not at all!** As we will see in the following section, setting K too high may end up separating data points that are actually pretty alike. At the extreme, we can set individual data points to be their own clusters (K=N) and achieve zero heterogeneity, but separating each data point into its own cluster is hardly a desirable outcome. In the following section, we will learn how to detect a K set \"too large\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize clusters of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start visualizing some clustering results to see if we think the clustering makes sense.  We can use such visualizations to help us assess whether we have set K too large or too small for a given application.  Following the theme of this course, we will judge whether the clustering makes sense in the context of document analysis.\n",
    "\n",
    "What are we looking for in a good clustering of documents?\n",
    "* Documents in the same cluster should be similar.\n",
    "* Documents from different clusters should be less similar.\n",
    "\n",
    "So a bad clustering exhibits either of two symptoms:\n",
    "* Documents in a cluster have mixed content.\n",
    "* Documents with similar content are divided up and put into different clusters.\n",
    "\n",
    "To help visualize the clustering, we do the following:\n",
    "* Fetch nearest neighbors of each centroid from the set of documents assigned to that cluster. We will consider these documents as being representative of the cluster.\n",
    "* Print titles and first sentences of those nearest neighbors.\n",
    "* Print top 5 words that have highest tf-idf weights in each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_document_clusters(wiki, tf_idf, centroids, cluster_assignment, k, map_index_to_word, display_content=True):\n",
    "    '''wiki: original dataframe\n",
    "       tf_idf: data matrix, sparse matrix format\n",
    "       map_index_to_word: SFrame specifying the mapping betweeen words and column indices\n",
    "       display_content: if True, display 8 nearest neighbors of each centroid'''\n",
    "    \n",
    "    print('==========================================================')\n",
    "\n",
    "    # Visualize each cluster c\n",
    "    for c in xrange(k):\n",
    "        # Cluster heading\n",
    "        print('Cluster {0:d}    '.format(c)),\n",
    "        # Print top 5 words with largest TF-IDF weights in the cluster\n",
    "        idx = centroids[c].argsort()[::-1]\n",
    "        for i in xrange(5): # Print each word along with the TF-IDF weight\n",
    "            print('{0:s}:{1:.3f}'.format(map_index_to_word.index[idx[i]], centroids[c,idx[i]])),\n",
    "        print('')\n",
    "        \n",
    "        if display_content:\n",
    "            # Compute distances from the centroid to all data points in the cluster,\n",
    "            # and compute nearest neighbors of the centroids within the cluster.\n",
    "            distances = pairwise_distances(tf_idf, centroids[c].reshape(1, -1), metric='euclidean').flatten()\n",
    "            distances[cluster_assignment!=c] = float('inf') # remove non-members from consideration\n",
    "            nearest_neighbors = distances.argsort()\n",
    "            # For 8 nearest neighbors, print the title as well as first 180 characters of text.\n",
    "            # Wrap the text at 80-character mark.\n",
    "            for i in xrange(8):\n",
    "                text = ' '.join(wiki.iloc[nearest_neighbors[i]]['text'].split(None, 25)[0:25])\n",
    "                print('\\n* {0:50s} {1:.5f}\\n  {2:s}\\n  {3:s}'.format(wiki.iloc[nearest_neighbors[i]]['name'],\n",
    "                    distances[nearest_neighbors[i]], text[:90], text[90:180] if len(text) > 90 else ''))\n",
    "        print('==========================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the 2 cluster case (K=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.00882137e-06,   0.00000000e+00,   2.88868244e-06, ...,\n",
       "          1.10291526e-04,   9.00609890e-05,   2.03703564e-05],\n",
       "       [  0.00000000e+00,   8.57526623e-06,   0.00000000e+00, ...,\n",
       "          1.38560691e-04,   6.46049863e-05,   2.26551103e-05]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids[2]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment[2]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     zwolsman:0.025 zx10r:0.017 zwigoff:0.012 zyuganovs:0.011 zyntherius:0.011 \n",
      "\n",
      "* Anita Kunz                                         0.97401\n",
      "  anita e kunz oc born 1956 is a canadianborn artist and illustratorkunz has lived in london\n",
      "   new york and toronto contributing to magazines and working\n",
      "\n",
      "* Janet Jackson                                      0.97472\n",
      "  janet damita jo jackson born may 16 1966 is an american singer songwriter and actress know\n",
      "  n for a series of sonically innovative socially conscious and\n",
      "\n",
      "* Madonna (entertainer)                              0.97475\n",
      "  madonna louise ciccone tkoni born august 16 1958 is an american singer songwriter actress \n",
      "  and businesswoman she achieved popularity by pushing the boundaries of lyrical\n",
      "\n",
      "* %C3%81ine Hyland                                   0.97536\n",
      "  ine hyland ne donlon is emeritus professor of education and former vicepresident of univer\n",
      "  sity college cork ireland she was born in 1942 in athboy co\n",
      "\n",
      "* Jane Fonda                                         0.97621\n",
      "  jane fonda born lady jayne seymour fonda december 21 1937 is an american actress writer po\n",
      "  litical activist former fashion model and fitness guru she is\n",
      "\n",
      "* Christine Robertson                                0.97643\n",
      "  christine mary robertson born 5 october 1948 is an australian politician and former austra\n",
      "  lian labor party member of the new south wales legislative council serving\n",
      "\n",
      "* Pat Studdy-Clift                                   0.97643\n",
      "  pat studdyclift is an australian author specialising in historical fiction and nonfictionb\n",
      "  orn in 1925 she lived in gunnedah until she was sent to a boarding\n",
      "\n",
      "* Alexandra Potter                                   0.97646\n",
      "  alexandra potter born 1970 is a british author of romantic comediesborn in bradford yorksh\n",
      "  ire england and educated at liverpool university gaining an honors degree in\n",
      "==========================================================\n",
      "Cluster 1     zvuku:0.040 zwerge:0.036 zwines:0.029 zumars:0.029 zx10rborn:0.028 \n",
      "\n",
      "* Todd Williams                                      0.95468\n",
      "  todd michael williams born february 13 1971 in syracuse new york is a former major league \n",
      "  baseball relief pitcher he attended east syracuseminoa high school\n",
      "\n",
      "* Gord Sherven                                       0.95622\n",
      "  gordon r sherven born august 21 1963 in gravelbourg saskatchewan and raised in mankota sas\n",
      "  katchewan is a retired canadian professional ice hockey forward who played\n",
      "\n",
      "* Justin Knoedler                                    0.95639\n",
      "  justin joseph knoedler born july 17 1980 in springfield illinois is a former major league \n",
      "  baseball catcherknoedler was originally drafted by the st louis cardinals\n",
      "\n",
      "* Chris Day                                          0.95648\n",
      "  christopher nicholas chris day born 28 july 1975 is an english professional footballer who\n",
      "   plays as a goalkeeper for stevenageday started his career at tottenham\n",
      "\n",
      "* Tony Smith (footballer, born 1957)                 0.95653\n",
      "  anthony tony smith born 20 february 1957 is a former footballer who played as a central de\n",
      "  fender in the football league in the 1970s and\n",
      "\n",
      "* Ashley Prescott                                    0.95761\n",
      "  ashley prescott born 11 september 1972 is a former australian rules footballer he played w\n",
      "  ith the richmond and fremantle football clubs in the afl between\n",
      "\n",
      "* Leslie Lea                                         0.95802\n",
      "  leslie lea born 5 october 1942 in manchester is an english former professional footballer \n",
      "  he played as a midfielderlea began his professional career with blackpool\n",
      "\n",
      "* Tommy Anderson (footballer)                        0.95818\n",
      "  thomas cowan tommy anderson born 24 september 1934 in haddington is a scottish former prof\n",
      "  essional footballer he played as a forward and was noted for\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "'''Notice the extra pairs of parentheses for centroids and cluster_assignment.\n",
    "   The centroid and cluster_assignment are still inside the npz file,\n",
    "   and we need to explicitly indicate when to load them into memory.'''\n",
    "visualize_document_clusters(wiki, tf_idf, centroids[2](), cluster_assignment[2](), 2, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both clusters have mixed content, although cluster 1 is much purer than cluster 0:\n",
    "* Cluster 0: artists, songwriters, professors, politicians, writers, etc.\n",
    "* Cluster 1: baseball players, hockey players, soccer (association football) players, etc.\n",
    "\n",
    "Top words of cluster 1 are all related to sports, whereas top words of cluster 0 show no clear pattern.\n",
    "\n",
    "Roughly speaking, the entire dataset was divided into athletes and non-athletes. It would be better if we sub-divided non-atheletes into more categories. So let us use more clusters. How about `K=10`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     zwacksalles:0.020 zuppiger:0.014 zyuganovs:0.011 zwangssterilisation:0.010 zwany:0.010 \n",
      "\n",
      "* Wilson McLean                                      0.97479\n",
      "  wilson mclean born 1937 is a scottish illustrator and artist he has illustrated primarily \n",
      "  in the field of advertising but has also provided cover art\n",
      "\n",
      "* Anton Hecht                                        0.97748\n",
      "  anton hecht is an english artist born in london in 2007 he asked musicians from around the\n",
      "   durham area to contribute to a soundtrack for\n",
      "\n",
      "* David Salle                                        0.97800\n",
      "  david salle born 1952 is an american painter printmaker and stage designer who helped defi\n",
      "  ne postmodern sensibility salle was born in norman oklahoma he earned\n",
      "\n",
      "* Vipin Sharma                                       0.97805\n",
      "  vipin sharma is an indian actor born in new delhi he is a graduate of national school of d\n",
      "  rama new delhi india and the canadian\n",
      "\n",
      "* Paul Swadel                                        0.97823\n",
      "  paul swadel is a new zealand film director and producerhe has directed and produced many s\n",
      "  uccessful short films which have screened in competition at cannes\n",
      "\n",
      "* Allan Stratton                                     0.97834\n",
      "  allan stratton born 1951 is a canadian playwright and novelistborn in stratford ontario st\n",
      "  ratton began his professional arts career while he was still in high\n",
      "\n",
      "* Bill Bennett (director)                            0.97848\n",
      "  bill bennett born 1953 is an australian film director producer and screenwriterhe dropped \n",
      "  out of medicine at queensland university in 1972 and joined the australian\n",
      "\n",
      "* Rafal Zielinski                                    0.97850\n",
      "  rafal zielinski born 1957 montreal is an independent filmmaker he is best known for direct\n",
      "  ing films such as fun sundance film festival special jury award\n",
      "==========================================================\n",
      "Cluster 1     zvuku:0.052 ziel:0.044 zvenigorodsky:0.042 zukko:0.042 zwerge:0.041 \n",
      "\n",
      "* Chris Day                                          0.93220\n",
      "  christopher nicholas chris day born 28 july 1975 is an english professional footballer who\n",
      "   plays as a goalkeeper for stevenageday started his career at tottenham\n",
      "\n",
      "* Gary Hooper                                        0.93481\n",
      "  gary hooper born 26 january 1988 is an english professional footballer who plays as a forw\n",
      "  ard for norwich cityhooper started his career at nonleague grays\n",
      "\n",
      "* Tony Smith (footballer, born 1957)                 0.93504\n",
      "  anthony tony smith born 20 february 1957 is a former footballer who played as a central de\n",
      "  fender in the football league in the 1970s and\n",
      "\n",
      "* Jason Roberts (footballer)                         0.93527\n",
      "  jason andre davis roberts mbe born 25 january 1978 is a former professional footballer and\n",
      "   now a football punditborn in park royal london roberts was\n",
      "\n",
      "* Paul Robinson (footballer, born 1979)              0.93587\n",
      "  paul william robinson born 15 october 1979 is an english professional footballer who plays\n",
      "   for blackburn rovers as a goalkeeper he is a former england\n",
      "\n",
      "* Alex Lawless                                       0.93732\n",
      "  alexander graham alex lawless born 26 march 1985 is a welsh professional footballer who pl\n",
      "  ays for luton town as a midfielderlawless began his career with\n",
      "\n",
      "* Neil Grayson                                       0.93748\n",
      "  neil grayson born 1 november 1964 in york is an english footballer who last played as a st\n",
      "  riker for sutton towngraysons first club was local\n",
      "\n",
      "* Sol Campbell                                       0.93759\n",
      "  sulzeer jeremiah sol campbell born 18 september 1974 is a former england international foo\n",
      "  tballer a central defender he had a 19year career playing in the\n",
      "==========================================================\n",
      "Cluster 2     zowie:0.040 zuberi:0.037 zululand:0.032 zyiit:0.029 zygouli:0.029 \n",
      "\n",
      "* Alessandra Aguilar                                 0.94505\n",
      "  alessandra aguilar born 1 july 1978 in lugo is a spanish longdistance runner who specialis\n",
      "  es in marathon running she represented her country in the event\n",
      "\n",
      "* Heather Samuel                                     0.94529\n",
      "  heather barbara samuel born 6 july 1970 is a retired sprinter from antigua and barbuda who\n",
      "   specialized in the 100 and 200 metres in 1990\n",
      "\n",
      "* Viola Kibiwot                                      0.94617\n",
      "  viola jelagat kibiwot born december 22 1983 in keiyo district is a runner from kenya who s\n",
      "  pecialises in the 1500 metres kibiwot won her first\n",
      "\n",
      "* Ayelech Worku                                      0.94636\n",
      "  ayelech worku born june 12 1979 is an ethiopian longdistance runner most known for winning\n",
      "   two world championships bronze medals on the 5000 metres she\n",
      "\n",
      "* Morhad Amdouni                                     0.94763\n",
      "  morhad amdouni born 21 january 1988 in portovecchio is a french middle and longdistance ru\n",
      "  nner he was european junior champion in track and cross country\n",
      "\n",
      "* Krisztina Papp                                     0.94776\n",
      "  krisztina papp born 17 december 1982 in eger is a hungarian long distance runner she is th\n",
      "  e national indoor record holder over 5000 mpapp began\n",
      "\n",
      "* Petra Lammert                                      0.94869\n",
      "  petra lammert born 3 march 1984 in freudenstadt badenwrttemberg is a former german shot pu\n",
      "  tter and current bobsledder she was the 2009 european indoor champion\n",
      "\n",
      "* Hasan Mahboob                                      0.94880\n",
      "  hasan mahboob ali born silas kirui on 31 december 1981 in kapsabet is a bahraini longdista\n",
      "  nce runner he became naturalized in bahrain and switched from\n",
      "==========================================================\n",
      "Cluster 3     zookeeper:0.110 zvuku:0.103 zvyozdami:0.052 zuzka:0.047 zwerge:0.045 \n",
      "\n",
      "* Steve Springer                                     0.89300\n",
      "  steven michael springer born february 11 1961 is an american former professional baseball \n",
      "  player who appeared in major league baseball as a third baseman and\n",
      "\n",
      "* Dave Ford                                          0.89547\n",
      "  david alan ford born december 29 1956 is a former major league baseball pitcher for the ba\n",
      "  ltimore orioles born in cleveland ohio ford attended lincolnwest\n",
      "\n",
      "* Todd Williams                                      0.89820\n",
      "  todd michael williams born february 13 1971 in syracuse new york is a former major league \n",
      "  baseball relief pitcher he attended east syracuseminoa high school\n",
      "\n",
      "* Justin Knoedler                                    0.90035\n",
      "  justin joseph knoedler born july 17 1980 in springfield illinois is a former major league \n",
      "  baseball catcherknoedler was originally drafted by the st louis cardinals\n",
      "\n",
      "* Kevin Nicholson (baseball)                         0.90643\n",
      "  kevin ronald nicholson born march 29 1976 is a canadian baseball shortstop he played part \n",
      "  of the 2000 season for the san diego padres of\n",
      "\n",
      "* James Baldwin (baseball)                           0.90648\n",
      "  james j baldwin jr born july 15 1971 is a former major league baseball pitcher he batted a\n",
      "  nd threw righthanded in his 11season career he\n",
      "\n",
      "* Joe Strong                                         0.90655\n",
      "  joseph benjamin strong born september 9 1962 in fairfield california is a former major lea\n",
      "  gue baseball pitcher who played for the florida marlins from 2000\n",
      "\n",
      "* Javier L%C3%B3pez (baseball)                       0.90691\n",
      "  javier alfonso lpez born july 11 1977 is a puerto rican professional baseball pitcher for \n",
      "  the san francisco giants of major league baseball he is\n",
      "==========================================================\n",
      "Cluster 4     zvezdy:0.038 zyntherius:0.035 zwane:0.032 zurichsalient:0.023 zvido:0.019 \n",
      "\n",
      "* Lawrence W. Green                                  0.95957\n",
      "  lawrence w green is best known by health education researchers as the originator of the pr\n",
      "  ecede model and codeveloper of the precedeproceed model which has\n",
      "\n",
      "* Timothy Luke                                       0.96057\n",
      "  timothy w luke is university distinguished professor of political science in the college o\n",
      "  f liberal arts and human sciences as well as program chair of\n",
      "\n",
      "* Ren%C3%A9e Fox                                     0.96100\n",
      "  rene c fox a summa cum laude graduate of smith college in 1949 earned her phd in sociology\n",
      "   in 1954 from radcliffe college harvard university\n",
      "\n",
      "* Francis Gavin                                      0.96323\n",
      "  francis j gavin is first frank stanton chair in nuclear security policy studies and profes\n",
      "  sor of political science at mit before joining mit he was\n",
      "\n",
      "* Catherine Hakim                                    0.96374\n",
      "  catherine hakim born 30 may 1948 is a british sociologist who specialises in womens employ\n",
      "  ment and womens issues she is currently a professorial research fellow\n",
      "\n",
      "* Stephen Park Turner                                0.96405\n",
      "  stephen turner is a researcher in social practice social and political theory and the phil\n",
      "  osophy of the social sciences he is graduate research professor in\n",
      "\n",
      "* Robert Bates (political scientist)                 0.96489\n",
      "  robert hinrichs bates born 1942 is an american political scientist he is eaton professor o\n",
      "  f the science of government in the departments of government and\n",
      "\n",
      "* Georg von Krogh                                    0.96505\n",
      "  georg von krogh was born in oslo norway he is a professor at eth zurich and holds the chai\n",
      "  r of strategic management and innovation he\n",
      "==========================================================\n",
      "Cluster 5     zumars:0.076 zuidams:0.060 ziza:0.056 zwerge:0.044 zx10rborn:0.037 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Todd Curley                                        0.92731\n",
      "  todd curley born 14 january 1973 is a former australian rules footballer who played for co\n",
      "  llingwood and the western bulldogs in the australian football league\n",
      "\n",
      "* Ashley Prescott                                    0.92992\n",
      "  ashley prescott born 11 september 1972 is a former australian rules footballer he played w\n",
      "  ith the richmond and fremantle football clubs in the afl between\n",
      "\n",
      "* Pete Richardson                                    0.93204\n",
      "  pete richardson born october 17 1946 in youngstown ohio is a former american football defe\n",
      "  nsive back in the national football league and former college head\n",
      "\n",
      "* Nathan Brown (Australian footballer born 1976)     0.93561\n",
      "  nathan daniel brown born 14 august 1976 is an australian rules footballer who played for t\n",
      "  he melbourne demons in the australian football leaguehe was drafted\n",
      "\n",
      "* Earl Spalding                                      0.93654\n",
      "  earl spalding born 11 march 1965 in south perth is a former australian rules footballer wh\n",
      "  o played for melbourne and carlton in the victorian football\n",
      "\n",
      "* Bud Grant                                          0.93766\n",
      "  harry peter bud grant jr born may 20 1927 is a former american football and canadian footb\n",
      "  all head coach grant served as the head coach\n",
      "\n",
      "* Tyrone Wheatley                                    0.93885\n",
      "  tyrone anthony wheatley born january 19 1972 is the running backs coach of michigan and a \n",
      "  former professional american football player who played 10 seasons\n",
      "\n",
      "* Nick Salter                                        0.93916\n",
      "  nick salter born 30 july 1987 is an australian rules footballer who played for port adelai\n",
      "  de football club in the australian football league aflhe was\n",
      "==========================================================\n",
      "Cluster 6     zwolsman:0.138 zx10r:0.089 zongkar:0.014 zwacksalles:0.013 zhongli:0.012 \n",
      "\n",
      "* Lauren Royal                                       0.93445\n",
      "  lauren royal born march 3 circa 1965 is a book writer from california royal has written bo\n",
      "  th historic and novelistic booksa selfproclaimed angels baseball fan\n",
      "\n",
      "* Barbara Hershey                                    0.93496\n",
      "  barbara hershey born barbara lynn herzstein february 5 1948 once known as barbara seagull \n",
      "  is an american actress in a career spanning nearly 50 years\n",
      "\n",
      "* Janet Jackson                                      0.93559\n",
      "  janet damita jo jackson born may 16 1966 is an american singer songwriter and actress know\n",
      "  n for a series of sonically innovative socially conscious and\n",
      "\n",
      "* Jane Fonda                                         0.93759\n",
      "  jane fonda born lady jayne seymour fonda december 21 1937 is an american actress writer po\n",
      "  litical activist former fashion model and fitness guru she is\n",
      "\n",
      "* Janine Shepherd                                    0.93833\n",
      "  janine lee shepherd am born 1962 is an australian pilot and former crosscountry skier shep\n",
      "  herds career as an athlete ended when she suffered major injuries\n",
      "\n",
      "* Ellina Graypel                                     0.93847\n",
      "  ellina graypel born july 19 1972 is an awardwinning russian singersongwriter she was born \n",
      "  near the volga river in the heart of russia she spent\n",
      "\n",
      "* Alexandra Potter                                   0.93858\n",
      "  alexandra potter born 1970 is a british author of romantic comediesborn in bradford yorksh\n",
      "  ire england and educated at liverpool university gaining an honors degree in\n",
      "\n",
      "* Melissa Hart (actress)                             0.93913\n",
      "  melissa hart is an american actress singer and teacher she made her broadway debut in 1966\n",
      "   as an ensemble member in jerry bocks the apple\n",
      "==========================================================\n",
      "Cluster 7     zwigoff:0.057 zupanprofessor:0.040 zulfiqar:0.035 zol:0.023 zwanenburg:0.022 \n",
      "\n",
      "* Brenton Broadstock                                 0.95722\n",
      "  brenton broadstock ao born 1952 is an australian composerbroadstock was born in melbourne \n",
      "  he studied history politics and music at monash university and later composition\n",
      "\n",
      "* Prince (musician)                                  0.96057\n",
      "  prince rogers nelson born june 7 1958 known by his mononym prince is an american singerson\n",
      "  gwriter multiinstrumentalist and actor he has produced ten platinum albums\n",
      "\n",
      "* Will.i.am                                          0.96066\n",
      "  william adams born march 15 1975 known by his stage name william pronounced will i am is a\n",
      "  n american rapper songwriter entrepreneur actor dj record\n",
      "\n",
      "* Tom Bancroft                                       0.96117\n",
      "  tom bancroft born 1967 london is a british jazz drummer and composer he began drumming age\n",
      "  d seven and started off playing jazz with his father\n",
      "\n",
      "* Julian Knowles                                     0.96152\n",
      "  julian knowles is an australian composer and performer specialising in new and emerging te\n",
      "  chnologies his creative work spans the fields of composition for theatre dance\n",
      "\n",
      "* Dan Siegel (musician)                              0.96223\n",
      "  dan siegel born in seattle washington is a pianist composer and record producer his earlie\n",
      "  r music has been described as new age while his more\n",
      "\n",
      "* Tony Mills (musician)                              0.96238\n",
      "  tony mills born 7 july 1962 in solihull england is an english rock singer best known for h\n",
      "  is work with shy and tnthailing from birmingham\n",
      "\n",
      "* Don Robertson (composer)                           0.96249\n",
      "  don robertson born 1942 is an american composerdon robertson was born in 1942 in denver co\n",
      "  lorado and began studying music with conductor and pianist antonia\n",
      "==========================================================\n",
      "Cluster 8     zhiyuan:0.216 zaruri:0.134 ziadahs:0.065 zwerge:0.053 zvuku:0.047 \n",
      "\n",
      "* Gord Sherven                                       0.83598\n",
      "  gordon r sherven born august 21 1963 in gravelbourg saskatchewan and raised in mankota sas\n",
      "  katchewan is a retired canadian professional ice hockey forward who played\n",
      "\n",
      "* Eric Brewer                                        0.83765\n",
      "  eric peter brewer born april 17 1979 is a canadian professional ice hockey defenceman for \n",
      "  the anaheim ducks of the national hockey league nhl he\n",
      "\n",
      "* Stephen Johns (ice hockey)                         0.84580\n",
      "  stephen johns born april 18 1992 is an american professional ice hockey defenceman he is c\n",
      "  urrently playing with the rockford icehogs of the american hockey\n",
      "\n",
      "* Mike Stevens (ice hockey, born 1965)               0.85320\n",
      "  mike stevens born december 30 1965 in kitchener ontario is a retired professional ice hock\n",
      "  ey player who played 23 games in the national hockey league\n",
      "\n",
      "* Tanner Glass                                       0.85484\n",
      "  tanner glass born november 29 1983 is a canadian professional ice hockey winger who plays \n",
      "  for the new york rangers of the national hockey league\n",
      "\n",
      "* Todd Strueby                                       0.86053\n",
      "  todd kenneth strueby born june 15 1963 in lanigan saskatchewan and raised in humboldt sask\n",
      "  atchewan is a retired canadian professional ice hockey centre who played\n",
      "\n",
      "* Steven King (ice hockey)                           0.86129\n",
      "  steven andrew king born july 22 1969 in east greenwich rhode island is a former ice hockey\n",
      "   forward who played professionally from 1991 to 2000\n",
      "\n",
      "* Don Jackson (ice hockey)                           0.86661\n",
      "  donald clinton jackson born september 2 1956 in minneapolis minnesota and bloomington minn\n",
      "  esota is an ice hockey coach and a retired professional ice hockey player\n",
      "==========================================================\n",
      "Cluster 9     zurichminds:0.028 zumadespite:0.025 zuffelato:0.025 zx81:0.021 zupan:0.019 \n",
      "\n",
      "* Doug Lewis                                         0.96516\n",
      "  douglas grinslade doug lewis pc qc born april 17 1938 is a former canadian politician a ch\n",
      "  artered accountant and lawyer by training lewis entered the\n",
      "\n",
      "* David Anderson (British Columbia politician)       0.96530\n",
      "  david a anderson pc oc born august 16 1937 in victoria british columbia is a former canadi\n",
      "  an cabinet minister educated at victoria college in victoria\n",
      "\n",
      "* Lucienne Robillard                                 0.96679\n",
      "  lucienne robillard pc born june 16 1945 is a canadian politician and a member of the liber\n",
      "  al party of canada she sat in the house\n",
      "\n",
      "* Bob Menendez                                       0.96686\n",
      "  robert bob menendez born january 1 1954 is the senior united states senator from new jerse\n",
      "  y he is a member of the democratic party first\n",
      "\n",
      "* Mal Sandon                                         0.96706\n",
      "  malcolm john mal sandon born 16 september 1945 is an australian politician he was an austr\n",
      "  alian labor party member of the victorian legislative council from\n",
      "\n",
      "* Roger Price (Australian politician)                0.96717\n",
      "  leo roger spurway price born 26 november 1945 is a former australian politician he was ele\n",
      "  cted as a member of the australian house of representatives\n",
      "\n",
      "* Maureen Lyster                                     0.96734\n",
      "  maureen anne lyster born 10 september 1943 is an australian politician she was an australi\n",
      "  an labor party member of the victorian legislative assembly from 1985\n",
      "\n",
      "* Don Bell                                           0.96739\n",
      "  donald h bell born march 10 1942 in new westminster british columbia is a canadian politic\n",
      "  ian he is currently serving as a councillor for the\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "visualize_document_clusters(wiki, tf_idf, centroids[k](), cluster_assignment[k](), k, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters 0, 1, and 5 appear to be still mixed, but others are quite consistent in content.\n",
    "* Cluster 0: artists, actors, film directors, playwrights\n",
    "* Cluster 1: soccer (association football) players, rugby players\n",
    "* Cluster 2: track and field athletes\n",
    "* Cluster 3: baseball players\n",
    "* Cluster 4: professors, researchers, scholars\n",
    "* Cluster 5: Austrailian rules football players, American football players\n",
    "* Cluster 6: female figures from various fields\n",
    "* Cluster 7: composers, songwriters, singers, music producers\n",
    "* Cluster 8: ice hockey players\n",
    "* Cluster 9: politicians\n",
    "\n",
    "Clusters are now more pure, but some are qualitatively \"bigger\" than others. For instance, the category of scholars is more general than the category of baseball players. Increasing the number of clusters may split larger clusters. Another way to look at the size of the clusters is to count the number of articles in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17602,  3415,  3535,  1736,  6445,  2552,  7106,  7155,   599,  8926])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment[10]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8926"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment[10]())[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17602"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.bincount(cluster_assignment[10]()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(np.bincount(cluster_assignment[10]()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    if np.bincount(cluster_assignment[10]())[i]==17602:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the 10 clusters above contains the greatest number of articles?\n",
    "\n",
    "1. Cluster 0: artists, actors, film directors, playwrights\n",
    "2. Cluster 4: professors, researchers, scholars\n",
    "3. Cluster 5: Austrailian rules football players, American football players\n",
    "4. Cluster 7: composers, songwriters, singers, music producers\n",
    "5. Cluster 9: politicians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the 10 clusters contains the least number of articles?\n",
    "\n",
    "1. Cluster 1: soccer (association football) players, rugby players\n",
    "2. Cluster 3: baseball players\n",
    "3. Cluster 6: female figures from various fields\n",
    "4. Cluster 7: composers, songwriters, singers, music producers\n",
    "5. Cluster 8: ice hockey players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be at least some connection between the topical consistency of a cluster and the number of its member data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the case for K=25. For the sake of brevity, we do not print the content of documents. It turns out that the top words with highest TF-IDF weights in each cluster are representative of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     zupan:0.077 zuddas:0.048 zts:0.046 zmajeviin:0.038 zombiethriller:0.038 \n",
      "==========================================================\n",
      "Cluster 1     zvezdy:0.054 zwane:0.033 zurichsalient:0.032 zyntherius:0.031 zhilabila:0.029 \n",
      "==========================================================\n",
      "Cluster 2     zhiyuan:0.216 zaruri:0.134 ziadahs:0.065 zwerge:0.052 zvuku:0.047 \n",
      "==========================================================\n",
      "Cluster 3     zurichminds:0.065 zumadespite:0.042 zuzana:0.031 zongon:0.027 zymans:0.023 \n",
      "==========================================================\n",
      "Cluster 4     zvakadaro:0.025 zwicky:0.023 zuleta:0.022 zurichandrey:0.022 zuni:0.020 \n",
      "==========================================================\n",
      "Cluster 5     zuffelato:0.160 zolile:0.056 zinmankillick:0.044 zurichminds:0.043 zumadespite:0.042 \n",
      "==========================================================\n",
      "Cluster 6     zyntherius:0.044 zwane:0.037 zurichsince:0.035 zvl:0.034 zmirs:0.031 \n",
      "==========================================================\n",
      "Cluster 7     zumadespite:0.066 yzfr7:0.058 zisman:0.051 zurichminds:0.045 zerounian:0.043 \n",
      "==========================================================\n",
      "Cluster 8     zimmermann:0.095 zagatcorson:0.056 zululand:0.054 zoobmg:0.052 yesno:0.051 \n",
      "==========================================================\n",
      "Cluster 9     zoheb:0.146 zoolander:0.096 zdorov:0.053 zow:0.048 zvezdy:0.043 \n",
      "==========================================================\n",
      "Cluster 10     zowie:0.075 zolecki:0.050 zadran:0.048 zealandamerican:0.048 zwolsman:0.048 \n",
      "==========================================================\n",
      "Cluster 11     zwolsman:0.144 zx10r:0.092 zhongli:0.016 zongkar:0.015 zwany:0.012 \n",
      "==========================================================\n",
      "Cluster 12     zyuganovs:0.011 zurichreally:0.009 zvika:0.009 zyryanovka:0.009 zyttrum:0.009 \n",
      "==========================================================\n",
      "Cluster 13     zookeeper:0.109 zvuku:0.104 zvyozdami:0.052 zuzka:0.047 zwerge:0.045 \n",
      "==========================================================\n",
      "Cluster 14     zuppiger:0.144 zoomermedia:0.076 zinter:0.056 zuraiqat:0.033 zvicka:0.031 \n",
      "==========================================================\n",
      "Cluster 15     zumars:0.125 zartman:0.060 zenterprise:0.051 zwerge:0.049 zx10rborn:0.045 \n",
      "==========================================================\n",
      "Cluster 16     zwigoff:0.097 zoghbi:0.061 zkms:0.033 zoomusicologythe:0.029 zol:0.028 \n",
      "==========================================================\n",
      "Cluster 17     zvuku:0.052 ziel:0.044 zvenigorodsky:0.043 zukko:0.042 zwerge:0.042 \n",
      "==========================================================\n",
      "Cluster 18     zionthe:0.055 zongamin:0.045 zwangssterilisation:0.042 zweite:0.039 zlatan:0.035 \n",
      "==========================================================\n",
      "Cluster 19     zwacksalles:0.095 zrichprofessor:0.038 zuco:0.035 zsuzsa:0.029 zwany:0.028 \n",
      "==========================================================\n",
      "Cluster 20     zupanprofessor:0.064 zulfiqar:0.049 zwigoff:0.037 zwanenburg:0.033 zubeck:0.025 \n",
      "==========================================================\n",
      "Cluster 21     zells:0.075 zoltyhe:0.066 zona:0.048 zombieadams:0.047 zeani:0.045 \n",
      "==========================================================\n",
      "Cluster 22     zol:0.146 zollo:0.116 zina:0.106 zemlinskys:0.077 zwigoff:0.064 \n",
      "==========================================================\n",
      "Cluster 23     ziza:0.120 zuidams:0.105 zehrudin:0.065 zunr:0.042 zwerge:0.040 \n",
      "==========================================================\n",
      "Cluster 24     zuberi:0.256 zadnji:0.213 zekiye:0.142 zorbu:0.073 zahur:0.062 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_document_clusters(wiki, tf_idf, centroids[25](), cluster_assignment[25](), 25,\n",
    "                            map_index_to_word, display_content=False) # turn off text for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looking at the representative examples and top words, we classify each cluster as follows. Notice the bolded items, which indicate the appearance of a new theme.\n",
    "* Cluster 0: **lawyers, judges, legal scholars**\n",
    "* Cluster 1: **professors, researchers, scholars (natural and health sciences)**\n",
    "* Cluster 2: ice hockey players\n",
    "* Cluster 3: politicans\n",
    "* Cluster 4: **government officials**\n",
    "* Cluster 5: politicans\n",
    "* Cluster 6: **professors, researchers, scholars (social sciences and humanities)**\n",
    "* Cluster 7: Canadian politicians\n",
    "* Cluster 8: **car racers**\n",
    "* Cluster 9: **economists**\n",
    "* Cluster 10: track and field athletes\n",
    "* Cluster 11: females from various fields\n",
    "* Cluster 12: (mixed; no clear theme)\n",
    "* Cluster 13: baseball players\n",
    "* Cluster 14: **painters, sculptors, artists**\n",
    "* Cluster 15: Austrailian rules football players, American football players\n",
    "* Cluster 16: **musicians, composers**\n",
    "* Cluster 17: soccer (association football) players, rugby players\n",
    "* Cluster 18: **poets**\n",
    "* Cluster 19: **film directors, playwrights**\n",
    "* Cluster 20: **songwriters, singers, music producers**\n",
    "* Cluster 21: **generals of U.S. Air Force**\n",
    "* Cluster 22: **music directors, conductors**\n",
    "* Cluster 23: **basketball players**\n",
    "* Cluster 24: **golf players**\n",
    "\n",
    "Indeed, increasing K achieved the desired effect of breaking up large clusters.  Depending on the application, this may or may not be preferable to the K=10 analysis.\n",
    "\n",
    "Let's take it to the extreme and set K=100. We have a suspicion that this value is too large. Let us look at the top words from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     zaroori:0.137 zhaos:0.082 zurichhe:0.056 zaiku:0.053 yurkovich:0.050 \n",
      "==========================================================\n",
      "Cluster 1     zells:0.170 youthwing:0.085 yuenron:0.083 zombieadams:0.072 zealandnicholas:0.058 \n",
      "==========================================================\n",
      "Cluster 2     zingzillas:0.247 zynk:0.069 yrsa:0.056 yorkcross:0.031 yaounde:0.029 \n",
      "==========================================================\n",
      "Cluster 3     yurchenko:0.181 zen3:0.121 yox:0.042 zedek:0.036 zwangssterilisation:0.034 \n",
      "==========================================================\n",
      "Cluster 4     zappa:0.309 zaheer:0.220 yigal:0.066 zarrella:0.041 wollesen:0.031 \n",
      "==========================================================\n",
      "Cluster 5     zori:0.192 zurichreally:0.127 zero1:0.054 zvika:0.046 zubr:0.042 \n",
      "==========================================================\n",
      "Cluster 6     zombiethriller:0.059 zuddas:0.053 zubieta:0.051 zunnit:0.049 zwinger:0.044 \n",
      "==========================================================\n",
      "Cluster 7     zheleznyak:0.105 zubaydah:0.099 zisman:0.071 zumadespite:0.067 zoppis:0.061 \n",
      "==========================================================\n",
      "Cluster 8     zoheb:0.065 zyntherius:0.048 zvezdy:0.045 zwane:0.043 zoolander:0.043 \n",
      "==========================================================\n",
      "Cluster 9     zorbain:0.086 zilbers:0.076 zsi:0.061 zonderling:0.053 zwozdesky:0.040 \n",
      "==========================================================\n",
      "Cluster 10     zwolsman:0.188 zx10r:0.052 zouaoui:0.026 zoloft:0.020 zurita:0.019 \n",
      "==========================================================\n",
      "Cluster 11     yakko:0.246 wendlinger:0.097 wushuguan:0.081 zolecki:0.073 zowie:0.068 \n",
      "==========================================================\n",
      "Cluster 12     zhamanak:0.086 zeturf:0.085 zhe:0.057 zatvor:0.038 zuppiger:0.025 \n",
      "==========================================================\n",
      "Cluster 13     zmajeviin:0.098 zombies:0.051 zuddas:0.044 zumadespite:0.043 zombiethriller:0.043 \n",
      "==========================================================\n",
      "Cluster 14     zol:0.227 zina:0.177 zenica:0.084 zwigoff:0.080 zemlinskys:0.057 \n",
      "==========================================================\n",
      "Cluster 15     zoltyhe:0.375 zona:0.242 zeani:0.106 zhvania:0.094 zigatela:0.080 \n",
      "==========================================================\n",
      "Cluster 16     zookeeper:0.098 zvuku:0.097 zionismin:0.083 zhurbinhis:0.083 zdravko:0.075 \n",
      "==========================================================\n",
      "Cluster 17     zombieadams:0.114 zebrafish:0.072 zaireamong:0.066 zantvan:0.047 zoeys:0.037 \n",
      "==========================================================\n",
      "Cluster 18     zubeck:0.071 zscore:0.043 zwigoff:0.041 zupanprofessor:0.030 zucko:0.025 \n",
      "==========================================================\n",
      "Cluster 19     ziza:0.165 zehrudin:0.113 zolakin:0.067 zwerge:0.044 yorkpineda:0.044 \n",
      "==========================================================\n",
      "Cluster 20     zuppiger:0.209 zoomermedia:0.186 zinter:0.082 zvicka:0.046 zoudiaris:0.044 \n",
      "==========================================================\n",
      "Cluster 21     zionthe:0.213 zeng6:0.083 zimphos:0.069 zaiters:0.044 znajoma:0.040 \n",
      "==========================================================\n",
      "Cluster 22     zoho:0.215 zki:0.045 zwigoff:0.045 yoreother:0.037 zmir:0.028 \n",
      "==========================================================\n",
      "Cluster 23     zongamin:0.127 zweite:0.045 zigiranyirazo:0.044 zwangssterilisation:0.039 zlatan:0.030 \n",
      "==========================================================\n",
      "Cluster 24     zoghbi:0.205 zwigoff:0.048 zulfiqar:0.034 zibrazibra:0.025 zuidlaren:0.023 \n",
      "==========================================================\n",
      "Cluster 25     zchtungsforschung:0.211 zemgalis:0.097 yudeng:0.091 westernised:0.039 zwolsman:0.023 \n",
      "==========================================================\n",
      "Cluster 26     yearfascher:0.259 xacar:0.178 wdvd:0.058 zah:0.033 vigorously:0.027 \n",
      "==========================================================\n",
      "Cluster 27     zuberi:0.261 zadnji:0.220 zekiye:0.140 zorbu:0.073 zahur:0.063 \n",
      "==========================================================\n",
      "Cluster 28     zartman:0.177 zumars:0.128 zubaydah:0.092 zanyiwe:0.064 zwerge:0.062 \n",
      "==========================================================\n",
      "Cluster 29     xsm:0.263 wwwaccessyouthacademyorg:0.107 zealandpsathas:0.095 zwolsman:0.066 ziadahs:0.060 \n",
      "==========================================================\n",
      "Cluster 30     zurichminds:0.073 zumadespite:0.035 zuzana:0.029 zornbergs:0.022 zongon:0.021 \n",
      "==========================================================\n",
      "Cluster 31     ziel:0.198 zukko:0.049 zwanej:0.046 zx10rborn:0.045 zixx:0.040 \n",
      "==========================================================\n",
      "Cluster 32     zwangssterilisation:0.039 zutty:0.029 zweite:0.026 zugdidi:0.021 zuru:0.017 \n",
      "==========================================================\n",
      "Cluster 33     zkms:0.150 zwigoff:0.071 zol:0.056 zrb:0.053 zibrazibra:0.051 \n",
      "==========================================================\n",
      "Cluster 34     yul:0.299 yahweh:0.163 yorviton:0.092 zululand:0.079 yenicarsimcom:0.078 \n",
      "==========================================================\n",
      "Cluster 35     zollo:0.269 zwolsman:0.067 zuce:0.041 zgerista:0.040 yosl:0.036 \n",
      "==========================================================\n",
      "Cluster 36     zurichreally:0.080 zvika:0.069 zohan:0.038 zre:0.030 zwany:0.028 \n",
      "==========================================================\n",
      "Cluster 37     zwigoff:0.131 ziesak:0.038 zoomusicologythe:0.037 zol:0.026 zielke:0.023 \n",
      "==========================================================\n",
      "Cluster 38     zhungzhung:0.099 zulfiqar:0.092 zupanprofessor:0.040 zenovich:0.039 zsfia:0.034 \n",
      "==========================================================\n",
      "Cluster 39     zcan:0.306 xkms:0.034 zx10r:0.021 zwolsman:0.020 zre:0.012 \n",
      "==========================================================\n",
      "Cluster 40     zngqn:0.086 zonebryan:0.072 zvezdy:0.045 zurichsalient:0.044 zteam:0.042 \n",
      "==========================================================\n",
      "Cluster 41     zuffelato:0.164 zolile:0.068 zinmankillick:0.043 zurichminds:0.039 zurmuhle:0.038 \n",
      "==========================================================\n",
      "Cluster 42     zvezdy:0.062 zwane:0.035 zyntherius:0.034 zurichsalient:0.031 zezizwe:0.030 \n",
      "==========================================================\n",
      "Cluster 43     zubr:0.127 zaragoza:0.062 zinhis:0.059 zwolsman:0.045 zeniff:0.045 \n",
      "==========================================================\n",
      "Cluster 44     zvuku:0.088 zor:0.060 zwerge:0.060 zvenigorodsky:0.059 zumars:0.055 \n",
      "==========================================================\n",
      "Cluster 45     zumars:0.046 zukko:0.044 zvenigorodsky:0.042 zwines:0.041 zvuku:0.033 \n",
      "==========================================================\n",
      "Cluster 46     zumars:0.108 ysaye:0.099 zubaydah:0.068 zimmers:0.067 zolfigol:0.064 \n",
      "==========================================================\n",
      "Cluster 47     zores:0.166 zentilli:0.119 yumng:0.058 yorkpoloncarz:0.038 zaslow:0.037 \n",
      "==========================================================\n",
      "Cluster 48     zmirs:0.227 yusof:0.045 zyntherius:0.044 zwane:0.041 yuranunt:0.041 \n",
      "==========================================================\n",
      "Cluster 49     zhilabila:0.121 zhakata:0.072 zamknity:0.060 zoellick:0.053 zwane:0.043 \n",
      "==========================================================\n",
      "Cluster 50     yousrys:0.070 zeitklang:0.060 yorkblumenthal:0.054 zuleta:0.035 zuzanaulkov:0.034 \n",
      "==========================================================\n",
      "Cluster 51     yonkersin:0.143 ziegfried:0.136 zacks:0.095 yongping:0.086 yinyin:0.064 \n",
      "==========================================================\n",
      "Cluster 52     zlatan:0.138 zombieland:0.069 zuidholland:0.054 zaverben:0.048 zoefrom:0.043 \n",
      "==========================================================\n",
      "Cluster 53     yesno:0.477 wroteproduced:0.121 zorba:0.091 youngher:0.078 xyz:0.072 \n",
      "==========================================================\n",
      "Cluster 54     zuena:0.122 zujovic:0.068 zone1:0.053 zirnhelt:0.049 wristwatch:0.028 \n",
      "==========================================================\n",
      "Cluster 55     zabaldu:0.282 yorklang:0.183 xlib:0.094 wxyt:0.046 winchmore:0.027 \n",
      "==========================================================\n",
      "Cluster 56     zemlinskys:0.207 zol:0.136 zealandcatran:0.087 zwigoff:0.080 zina:0.073 \n",
      "==========================================================\n",
      "Cluster 57     zinovievana:0.035 zombajive:0.027 zieglers:0.026 zts:0.025 zestcash:0.023 \n",
      "==========================================================\n",
      "Cluster 58     zidanes:0.234 zulfiqar:0.047 zwigoff:0.039 zupanprofessor:0.037 zoho:0.035 \n",
      "==========================================================\n",
      "Cluster 59     zevenheuvelenloopher:0.093 zalacains:0.052 zarkana:0.051 zwigoff:0.048 zupanprofessor:0.037 \n",
      "==========================================================\n",
      "Cluster 60     zurichhe:0.127 zuce:0.059 zimbabweancayeux:0.035 zlat:0.026 zealandbased:0.025 \n",
      "==========================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 61     zhi:0.193 yearkristock:0.132 ziauddin:0.052 zaimovzaimov:0.038 you:0.032 \n",
      "==========================================================\n",
      "Cluster 62     zapiski:0.362 znith:0.109 zealandtongan:0.084 zwolsman:0.057 yatchman:0.044 \n",
      "==========================================================\n",
      "Cluster 63     zhiyuan:0.220 zaruri:0.138 ziadahs:0.067 zwerge:0.053 zvuku:0.048 \n",
      "==========================================================\n",
      "Cluster 64     zupan:0.148 zts:0.093 zoku:0.071 zuddas:0.051 zoneplex:0.043 \n",
      "==========================================================\n",
      "Cluster 65     zuidams:0.205 zunr:0.086 ziza:0.059 zire:0.052 zumars:0.046 \n",
      "==========================================================\n",
      "Cluster 66     years100:0.278 wwwnaturebridgeorg:0.168 woodcuts:0.100 troyon:0.055 yearsit:0.031 \n",
      "==========================================================\n",
      "Cluster 67     zupanprofessor:0.088 zwanenburg:0.044 zwigoff:0.040 zuken:0.033 zpdas:0.027 \n",
      "==========================================================\n",
      "Cluster 68     zwolsman:0.158 zx10r:0.152 zwigoff:0.020 zupanprofessor:0.016 zucko:0.013 \n",
      "==========================================================\n",
      "Cluster 69     zrichprofessor:0.194 zsuzsa:0.034 zuffar:0.031 zuska:0.029 zsa:0.027 \n",
      "==========================================================\n",
      "Cluster 70     zrichin:0.099 zondag:0.089 zinkin:0.086 zvezdy:0.039 zaubersee:0.039 \n",
      "==========================================================\n",
      "Cluster 71     zulm:0.145 zongon:0.115 zurichminds:0.053 zymans:0.049 zunnit:0.048 \n",
      "==========================================================\n",
      "Cluster 72     zadran:0.459 zolzer:0.087 zwolsman:0.082 zillmere:0.063 zowie:0.062 \n",
      "==========================================================\n",
      "Cluster 73     zwolsman:0.147 zx10r:0.105 zongkar:0.098 zwacksalles:0.063 zverev:0.054 \n",
      "==========================================================\n",
      "Cluster 74     zwolsman:0.101 zx10r:0.065 zouaoui:0.012 zvika:0.010 zwany:0.009 \n",
      "==========================================================\n",
      "Cluster 75     yola:0.196 zombieadams:0.177 yeok:0.099 youafter:0.074 yakovlevna:0.073 \n",
      "==========================================================\n",
      "Cluster 76     zebre:0.242 wwwthebenoitagencycomheaston:0.064 yoshiyuki:0.061 zuffelato:0.059 wzenorg:0.051 \n",
      "==========================================================\n",
      "Cluster 77     zwacksalles:0.233 zulu:0.085 zuco:0.048 zooom:0.048 zoran:0.045 \n",
      "==========================================================\n",
      "Cluster 78     zhancen:0.288 zeynaal:0.268 zionistpalestinian:0.068 zobari:0.037 yankeeshe:0.035 \n",
      "==========================================================\n",
      "Cluster 79     zetor:0.296 zvuku:0.072 zaporizia:0.065 zwines:0.053 zwerge:0.052 \n",
      "==========================================================\n",
      "Cluster 80     zyuganovs:0.011 zyryanovka:0.009 zyttrum:0.009 zyiit:0.008 zyl:0.007 \n",
      "==========================================================\n",
      "Cluster 81     zo:0.092 zongyuanin:0.072 zumadespite:0.072 zj:0.066 wydra:0.054 \n",
      "==========================================================\n",
      "Cluster 82     zohnmuldoon:0.048 zwerling:0.047 zsa:0.043 zwany:0.038 zverev:0.037 \n",
      "==========================================================\n",
      "Cluster 83     zimmermann:0.128 zagatcorson:0.080 zoobmg:0.066 zimansky:0.061 zengrden:0.055 \n",
      "==========================================================\n",
      "Cluster 84     zumadespite:0.096 yzfr7:0.086 zisman:0.071 zurichminds:0.067 zinni:0.060 \n",
      "==========================================================\n",
      "Cluster 85     zurichandrey:0.038 zvi:0.031 zuleta:0.027 zmichknight:0.025 zubareva:0.023 \n",
      "==========================================================\n",
      "Cluster 86     youngsam:0.414 yeartarry:0.085 yeardonohue:0.066 zululand:0.064 xlperlman:0.059 \n",
      "==========================================================\n",
      "Cluster 87     zajednicahdz:0.077 zahi:0.068 yussuff:0.057 zumba:0.048 zorbu:0.047 \n",
      "==========================================================\n",
      "Cluster 88     zwicky:0.038 zx81:0.028 zvakadaro:0.028 zyntherius:0.026 zupcu:0.022 \n",
      "==========================================================\n",
      "Cluster 89     zpafhe:0.061 zivira:0.054 zurlini:0.047 zmajeviin:0.037 zhiqiang:0.037 \n",
      "==========================================================\n",
      "Cluster 90     zumars:0.120 zenterprise:0.106 zahnow:0.081 zeffirelliin:0.052 youthkhnen:0.041 \n",
      "==========================================================\n",
      "Cluster 91     zookeeper:0.117 zvuku:0.108 zoell:0.061 zvyozdami:0.052 zeffiretto:0.044 \n",
      "==========================================================\n",
      "Cluster 92     zupanprofessor:0.115 zx10r:0.073 zerbinetta:0.066 zerzan:0.064 zisel:0.064 \n",
      "==========================================================\n",
      "Cluster 93     zwacksalles:0.087 zuco:0.050 zsuzsa:0.029 zwany:0.024 zsa:0.022 \n",
      "==========================================================\n",
      "Cluster 94     zowie:0.106 zealandamerican:0.086 zwolsman:0.059 zosta:0.059 zhjn:0.054 \n",
      "==========================================================\n",
      "Cluster 95     zuppiger:0.109 zinter:0.040 zuraiqat:0.036 zemliansky:0.032 zhongyun:0.032 \n",
      "==========================================================\n",
      "Cluster 96     zulfiqar:0.120 zupanprofessor:0.040 zoeshe:0.035 zindell:0.031 zsfia:0.030 \n",
      "==========================================================\n",
      "Cluster 97     zhongli:0.361 yps:0.209 zrichhe:0.127 zwolsman:0.110 zaks:0.063 \n",
      "==========================================================\n",
      "Cluster 98     yorta:0.155 yzr500:0.120 zosta:0.119 youbou:0.090 zapanta:0.075 \n",
      "==========================================================\n",
      "Cluster 99     zolot:0.081 zhvania:0.080 zeani:0.076 zoohe:0.076 zoriah:0.058 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "k=100\n",
    "visualize_document_clusters(wiki, tf_idf, centroids[k](), cluster_assignment[k](), k,\n",
    "                            map_index_to_word, display_content=False)\n",
    "# turn off text for brevity -- turn it on if you are curious ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of soccer (association football) players has been broken into two clusters (44 and 45). Same goes for Austrialian rules football players (clusters 26 and 48). The class of baseball players have been also broken into two clusters (16 and 91).\n",
    "\n",
    "**A high value of K encourages pure clusters, but we cannot keep increasing K. For large enough K, related documents end up going to different clusters.**\n",
    "\n",
    "That said, the result for K=100 is not entirely bad. After all, it gives us separate clusters for such categories as Brazil, wrestling, computer science and the Mormon Church. If we set K somewhere between 25 and 100, we should be able to avoid breaking up clusters while discovering new ones.\n",
    "\n",
    "Also, we should ask ourselves how much **granularity** we want in our clustering. If we wanted a rough sketch of Wikipedia, we don't want too detailed clusters. On the other hand, having many clusters can be valuable when we are zooming into a certain part of Wikipedia.\n",
    "\n",
    "**There is no golden rule for choosing K. It all depends on the particular application and domain we are in.**\n",
    "\n",
    "Another heuristic people use that does not rely on so much visualization, which can be hard in many applications (including here!) is as follows.  Track heterogeneity versus K and look for the \"elbow\" of the curve where the heterogeneity decrease rapidly before this value of K, but then only gradually for larger values of K.  This naturally trades off between trying to minimize heterogeneity, but reduce model complexity.  In the heterogeneity versus K plot made above, we did not yet really see a flattening out of the heterogeneity, which might indicate that indeed K=100 is \"reasonable\" and we only see real overfitting for larger values of K (which are even harder to visualize using the methods we attempted above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**. Another sign of too large K is having lots of small clusters. Look at the distribution of cluster sizes (by number of member data points). How many of the 100 clusters have fewer than 236 articles, i.e. 0.4% of the dataset?\n",
    "\n",
    "Hint: Use `cluster_assignment[100]()`, with the extra pair of parentheses for delayed loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_size=np.bincount(cluster_assignment[100]())\n",
    "count=0\n",
    "for i in cluster_size:\n",
    "    if i<236:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "\n",
    "Keep in mind though that tiny clusters aren't necessarily bad. A tiny cluster of documents that really look like each others is definitely preferable to a medium-sized cluster of documents with mixed content. However, having too few articles in a cluster may cause overfitting by reading too much into a limited pool of training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
